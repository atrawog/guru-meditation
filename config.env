#
# Ollama Configuration
#
# Host and port for Ollama
OLLAMA_HOST="127.0.0.1:11434" 

# Path to Ollama models
OLLAMA_MODELS="/workspace/data/models/ollama"

# Keep-alive duration for Ollama
OLLAMA_KEEP_ALIVE="5m"

# Enable or disable debug mode for Ollama
OLLAMA_DEBUG="true"

# CUDA Configuration
CUDA_VISIBLE_DEVICES=0

# Huggingface
HF_HOME=/workspace/data/models/huggingface

#
# Host Configuration
#

# Hostname for the container
HOSTNAME=gurum 



# Ollama
OLLAMA_ENABLE=false
ENABLE_OLLAMA_API=false
ENABLE_OPENAI_API=true

# ENV Vars 
USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 Edg/131.0.2903.86"
XDG_CACHE_HOME=/workspace/.cache
UV_CACHE_DIR=/workspace/.cache/uv

# OpenWebUI
OW_ENABLE=true
OW_DATA_DIR=/workspace/data/openwebui/devel
OW_PORT=3001


# MCPO
MCPO_ENABLE=true
MCPO_PORT=8011
MCPO_CONFIG=/workspace/config/mcpo/devel/mcpo.json


# JupyterHub

JH_ENABLE=false
JH_PORT=8021
JH_CONFIG=/workspace/config/jupyterhub/devel/jupyterhub.py
JH_DATA_DIR=/workspace/data/jupyterhub/devel

# JupyterServer
JS_ENABLE=true
JS_PORT=8031
JS_CONFIG=/workspace/config/jupyterserver/devel/jupyterserver.py
JS_DATA_DIR=/workspace/data/jupyterserver/devel
